{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Sequential models without an `input_shape` passed to the first layer cannot reload their optimizer state. As a result, your model isstarting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "### Batch Predictions starts\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "#STEP 0: if LSTM model not loaded then load the file \n",
    "BASE_DATA_PATH = 'C:\\\\Users\\\\STSC\\\\Desktop\\\\CV-Indoor\\\\'\n",
    "saved_model_dir = os.path.join(BASE_DATA_PATH, 'my_model_.h5')\n",
    "model = tf.keras.models.load_model(saved_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking (Masking)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  multiple                  3672064   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  131328    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  514       \n",
      "=================================================================\n",
      "Total params: 3,803,906\n",
      "Trainable params: 3,803,906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Check its architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<DatasetV1Adapter shapes: ((224, 224, 3), ()), types: (tf.float32, tf.string)>\n"
     ]
    }
   ],
   "source": [
    "#function to retrieve the next image in the set of image to extract from a video clip\n",
    "def single_video_frame_generator():\n",
    "    frames = []\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    SEQUENCE_LENGTH = 40\n",
    "    num_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    sample_every_frame = max(1, num_frames // SEQUENCE_LENGTH)\n",
    "    current_frame = 0\n",
    "\n",
    "    label = os.path.basename(os.path.dirname(video_path))\n",
    "    \n",
    "\n",
    "\n",
    "    max_images = SEQUENCE_LENGTH\n",
    "    while True:\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        if current_frame % sample_every_frame == 0:\n",
    "            # OPENCV reads in BGR, tensorflow expects RGB so we invert the order\n",
    "            frame = frame[:, :, ::-1]\n",
    "            img = tf.image.resize(frame, (224, 224))\n",
    "            img = tf.keras.applications.mobilenet_v2.preprocess_input(img)\n",
    "            max_images -= 1\n",
    "            yield img, video_path\n",
    "\n",
    "        if max_images == 0:\n",
    "            break\n",
    "        current_frame += 1\n",
    "\n",
    "\n",
    "#create a Dataset using the prevous function frame_generator        \n",
    "# `from_generator` might throw a warning, expected to disappear in upcoming versions:\n",
    "dataset = tf.data.Dataset.from_generator(single_video_frame_generator,\n",
    "             output_types=(tf.float32, tf.string),\n",
    "             output_shapes=((224, 224, 3), ()))\n",
    "\n",
    "#dataset = dataset.batch(16).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet_v2 = tf.keras.applications.mobilenet_v2.MobileNetV2(input_shape=(224,224,3), include_top=False, weights='imagenet')\n",
    "x = mobilenet_v2.output\n",
    "\n",
    "# We add Average Pooling to transform the feature map from\n",
    "# 8 * 8 * 2048 to 1 x 2048, as we don't need spatial information\n",
    "pooling_output = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "feature_extraction_model = tf.keras.Model(mobilenet_v2.input,pooling_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 3:  Now process the images in our dataSet with the MobileNet feature extraction model created prevously\n",
    "#\n",
    "#IMPORTANT:   the conversion from tensor object to numpy array ONLY WORKS IN TF 2.* !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "\n",
    "# step 3.1 create function to go through video specified and return an array of images of length SEQUNCE_LENGTH\n",
    "#          each image is resized and preprocessed for input into a FeatureExtractor MobileNet\n",
    "#          returns array of tenors (1 tensor per image)\n",
    "def grabImagesFromVideo_PreProcess_for_MobileNet_FeatureExtractor(video_path):\n",
    "    #print(\" going to process \" + str(video_path))\n",
    "    frames = []\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    num_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    sample_every_frame = max(1, num_frames // SEQUENCE_LENGTH)\n",
    "    max_images = SEQUENCE_LENGTH\n",
    " \n",
    "    #cycle through the frames in the video\n",
    "    for current_frame_index in range(num_frames):\n",
    "        \n",
    "        #print(\"on frame\" + str(current_frame_index))\n",
    "\n",
    "        #read in next frame from video\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        #take every kth(sample_every_frame) frame and store in frames array\n",
    "        if current_frame_index % sample_every_frame == 0:\n",
    "            # OPENCV reads in BGR, tensorflow expects RGB so we invert the order\n",
    "            frame = frame[:, :, ::-1]\n",
    "            #appropriately resize and preprocess the image for Feature Extraction with inceptionV3 CNN\n",
    "            img = tf.image.resize(frame, (224, 224))\n",
    "            #img = tf.keras.applications.inception_v3.preprocess_input(img)\n",
    "            img = tf.keras.applications.mobilenet_v2.preprocess_input(img)\n",
    "#             print(\" going to save image\")\n",
    "#             print(img)\n",
    "#             print(img[0])\n",
    "#             print(img[0][0])\n",
    "\n",
    "            frames.append(img)\n",
    "            max_images -= 1\n",
    "           \n",
    "        # if we have sampled SEQUENCE_LENGTH number of frames then stop\n",
    "        if max_images == 0:\n",
    "            break\n",
    "    return frames\n",
    "            \n",
    "# step 3.1 create function to go through video specified and return an array of images of lenght SEQUNCE_LENGTH\n",
    "#          each image is resized and preprocessed for input into a FeatureExtractor InceptionV3 CNN\n",
    "#          then run through the FeatureExtractor --output will be a 1x2048 feature vector for each image\n",
    "#          append to the set of features and return\n",
    "#          features is an array of SEQUENCE_LENGTH (40) Tensors (each 1x2048 in length)\n",
    "\n",
    "def grabImagesFromVideo_Process_with_MobileNet_FeatureExtractor(video_path, feature_extraction_model):\n",
    "    #print(\" going to process \" + str(video_path))\n",
    "    features = []\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    num_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    sample_every_frame = max(1, num_frames // SEQUENCE_LENGTH)\n",
    " \n",
    "    max_images = SEQUENCE_LENGTH\n",
    "    #cycle through the frames in the video\n",
    "    for current_frame_index in range(num_frames):\n",
    "        \n",
    "        #print(\"     on frame\" + str(current_frame_index))\n",
    "\n",
    "        #read in next frame from video\n",
    "        success, frame = cap.read()\n",
    "            \n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        #take every kth(sample_every_frame) frame and store in frames array\n",
    "        if current_frame_index % sample_every_frame == 0:\n",
    "            # OPENCV reads in BGR, tensorflow expects RGB so we invert the order\n",
    "            frame = frame[:, :, ::-1]\n",
    "              \n",
    "            #appropriately resize and preprocess the image for Feature Extraction with inceptionV3 CNN\n",
    "            # CONVERTS TO A TENSOR from an array   with the size of 299x299\n",
    "            img = tf.image.resize(frame, (224, 224))\n",
    "           \n",
    "            #img = tf.keras.applications.inception_v3.preprocess_input(img)\n",
    "            img = tf.keras.applications.mobilenet_v2.preprocess_input(img)\n",
    "            \n",
    "            #print(\" img currently is:\")\n",
    "            #print(img)\n",
    "            #print(\" img shape is \" + str(img.shape))\n",
    "            tensor_input = tf.expand_dims(img,axis=0)\n",
    "            #print(\" expanded dimension tensor now is \" + str(tensor_input))\n",
    "            #print(\"     --shape is\" + str(tensor_input.shape))\n",
    "            #Diagnostics: run the \"graph\" to print out tensor object\n",
    "            if(False):\n",
    "                with tf.Session() as sess:\n",
    "                    sess.run(init_op) #execute init_op\n",
    "                    print('the random values that we sample')\n",
    "                    print(\" content img\")\n",
    "                    print (sess.run(img))\n",
    "                    print(\" _________________\")\n",
    "\n",
    "                    print(\" expanded dimension tensor now is \" + str(tensor_input))\n",
    "                    print(\"     --shape is\" + str(tensor_input.shape))\n",
    "                    print(\" content tensor_input\")\n",
    "                    print (sess.run(tensor_input))\n",
    "\n",
    "         \n",
    "            # now going to process with the feature extraction model (MobileNet based)\n",
    "            current_features = feature_extraction_model(tensor_input)\n",
    "            \n",
    "            #current_features = feature_extraction_model.predict(img, steps=1)\n",
    "            #reshape the tensor to shape ( #features x 1)--see https://www.tensorflow.org/api_docs/python/tf/reshape\n",
    "            current_features = tf.reshape(current_features, (current_features.shape[0], -1))\n",
    "            \n",
    "            #convert tensor current_features to an numpy array !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "            #only works in TF 2.* !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "            current_features = current_features.numpy()\n",
    "            \n",
    "            features.append(current_features)\n",
    "    \n",
    "            #reduce counter\n",
    "            max_images -= 1\n",
    "           \n",
    "        # if we have sampled SEQUENCE_LENGTH number of frames then stop\n",
    "        if max_images == 0:\n",
    "            break\n",
    "    \n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data for all video files generated in a list\n",
    "gen_list_path = 'C:/Users/STSC/Desktop/CV-Indoor/Batch_Predictions/filenames.txt'\n",
    "with open(gen_list_path) as f:\n",
    "    file_list = [row.strip() for row in list(f)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\STSC\\Desktop\\CV-Indoor\\Batch_Predictions\\Doors\\VID_20191201_011325053.mp4\n",
      "Prediction:::\n",
      "[[1.16993277e-07 9.99999881e-01]\n",
      " [1.49868626e-07 9.99999881e-01]\n",
      " [7.47531175e-08 9.99999881e-01]\n",
      " [1.10521363e-07 9.99999881e-01]\n",
      " [1.02813090e-07 9.99999881e-01]\n",
      " [3.58313166e-08 1.00000000e+00]\n",
      " [4.81829368e-08 1.00000000e+00]\n",
      " [1.03031972e-07 9.99999881e-01]\n",
      " [1.11623628e-07 9.99999881e-01]\n",
      " [1.09102984e-07 9.99999881e-01]\n",
      " [4.14795238e-08 1.00000000e+00]\n",
      " [1.22546578e-06 9.99998808e-01]\n",
      " [8.95481733e-08 9.99999881e-01]\n",
      " [5.18460979e-07 9.99999523e-01]\n",
      " [6.33051940e-08 9.99999881e-01]\n",
      " [2.62459707e-08 1.00000000e+00]\n",
      " [2.71744653e-08 1.00000000e+00]\n",
      " [4.61963232e-08 1.00000000e+00]\n",
      " [1.39818596e-07 9.99999881e-01]\n",
      " [5.63179128e-07 9.99999404e-01]\n",
      " [6.29071508e-07 9.99999404e-01]\n",
      " [1.70301192e-07 9.99999881e-01]\n",
      " [4.18658139e-08 1.00000000e+00]\n",
      " [3.73655702e-08 1.00000000e+00]\n",
      " [7.08787198e-08 9.99999881e-01]\n",
      " [1.79503047e-07 9.99999762e-01]\n",
      " [2.49647769e-07 9.99999762e-01]\n",
      " [3.48951716e-07 9.99999642e-01]\n",
      " [2.16105903e-07 9.99999762e-01]\n",
      " [2.28507009e-08 1.00000000e+00]\n",
      " [4.62237359e-08 1.00000000e+00]\n",
      " [4.46240822e-09 1.00000000e+00]\n",
      " [2.47144150e-09 1.00000000e+00]\n",
      " [1.56778057e-08 1.00000000e+00]\n",
      " [1.07337117e-08 1.00000000e+00]\n",
      " [2.28968595e-08 1.00000000e+00]\n",
      " [2.19206324e-08 1.00000000e+00]\n",
      " [4.63601291e-09 1.00000000e+00]\n",
      " [6.09896134e-08 9.99999881e-01]\n",
      " [7.80549403e-09 1.00000000e+00]]\n",
      "length of predictions- 40\n",
      "for prediction 0\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 1\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 2\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 3\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 4\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 5\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 6\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 7\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 8\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 9\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 10\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 11\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 12\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 13\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 14\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 15\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 16\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 17\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 18\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 19\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 20\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 21\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 22\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 23\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 24\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 25\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 26\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 27\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 28\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 29\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 30\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 31\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 32\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 33\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 34\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 35\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 36\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 37\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 38\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 39\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "C:\\Users\\STSC\\Desktop\\CV-Indoor\\Batch_Predictions\\Doors\\VID_20191201_011408302.mp4\n",
      "Prediction:::\n",
      "[[5.0542692e-08 1.0000000e+00]\n",
      " [3.2000418e-08 1.0000000e+00]\n",
      " [8.1210636e-08 9.9999988e-01]\n",
      " [8.6446292e-08 9.9999988e-01]\n",
      " [2.3031633e-08 1.0000000e+00]\n",
      " [9.6963610e-09 1.0000000e+00]\n",
      " [1.9067656e-08 1.0000000e+00]\n",
      " [1.1788991e-08 1.0000000e+00]\n",
      " [6.2481065e-09 1.0000000e+00]\n",
      " [3.3947778e-08 1.0000000e+00]\n",
      " [3.2495425e-08 1.0000000e+00]\n",
      " [1.1475111e-07 9.9999988e-01]\n",
      " [3.6820314e-08 1.0000000e+00]\n",
      " [4.2183794e-07 9.9999952e-01]\n",
      " [2.4992497e-08 1.0000000e+00]\n",
      " [7.9397626e-09 1.0000000e+00]\n",
      " [1.2550321e-08 1.0000000e+00]\n",
      " [2.1623553e-08 1.0000000e+00]\n",
      " [3.0032325e-08 1.0000000e+00]\n",
      " [3.9409715e-06 9.9999607e-01]\n",
      " [5.8726016e-08 1.0000000e+00]\n",
      " [1.5234948e-08 1.0000000e+00]\n",
      " [1.8577346e-08 1.0000000e+00]\n",
      " [1.2620944e-08 1.0000000e+00]\n",
      " [2.6861107e-07 9.9999976e-01]\n",
      " [1.6575864e-06 9.9999833e-01]\n",
      " [3.9484246e-07 9.9999964e-01]\n",
      " [1.3617789e-08 1.0000000e+00]\n",
      " [2.0002751e-08 1.0000000e+00]\n",
      " [4.8043539e-08 1.0000000e+00]\n",
      " [1.7489523e-08 1.0000000e+00]\n",
      " [1.1272657e-07 9.9999988e-01]\n",
      " [3.6282604e-08 1.0000000e+00]\n",
      " [3.4570431e-07 9.9999964e-01]\n",
      " [1.7234725e-06 9.9999833e-01]\n",
      " [1.0391591e-06 9.9999893e-01]\n",
      " [4.4348173e-08 1.0000000e+00]\n",
      " [8.8642771e-08 9.9999988e-01]\n",
      " [2.6727612e-08 1.0000000e+00]\n",
      " [1.5644342e-07 9.9999988e-01]]\n",
      "length of predictions- 40\n",
      "for prediction 0\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 1\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 2\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 3\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 4\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 5\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 6\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 7\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 8\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 9\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 10\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 11\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 12\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 13\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 14\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 15\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 16\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 17\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 18\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 19\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 20\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 21\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 22\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 23\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 24\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 25\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 26\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 27\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 28\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 29\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 30\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 31\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 32\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 33\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 34\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 35\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 36\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 37\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 38\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "for prediction 39\n",
      "index of max predicition class \n",
      "Doors-  1\n",
      "C:\\Users\\STSC\\Desktop\\CV-Indoor\\Batch_Predictions\\Stairs\\VID_20191201_201817673.mp4\n",
      "Prediction:::\n",
      "[[9.9999976e-01 2.1210316e-07]\n",
      " [9.9999964e-01 3.2303365e-07]\n",
      " [9.9999988e-01 1.5801439e-07]\n",
      " [9.9999976e-01 2.3211970e-07]\n",
      " [9.9999964e-01 4.1506675e-07]\n",
      " [9.9999964e-01 3.4303298e-07]\n",
      " [9.9999964e-01 3.1490273e-07]\n",
      " [9.9999964e-01 3.8587402e-07]\n",
      " [9.9999976e-01 2.9721707e-07]\n",
      " [9.9999976e-01 2.7871158e-07]\n",
      " [9.9999976e-01 2.9529050e-07]\n",
      " [9.9999952e-01 4.9522589e-07]\n",
      " [9.9999976e-01 2.7213997e-07]\n",
      " [9.9999964e-01 3.3782104e-07]\n",
      " [9.9999976e-01 2.7943923e-07]\n",
      " [9.9999976e-01 1.8635092e-07]\n",
      " [9.9999976e-01 2.7479436e-07]\n",
      " [9.9999976e-01 2.5717185e-07]\n",
      " [9.9999964e-01 3.4983407e-07]\n",
      " [9.9999952e-01 4.1732673e-07]\n",
      " [9.9999976e-01 2.5525085e-07]\n",
      " [9.9999976e-01 2.5183576e-07]\n",
      " [9.9999976e-01 2.9098513e-07]\n",
      " [9.9999964e-01 3.2982993e-07]\n",
      " [9.9999964e-01 3.2319144e-07]\n",
      " [9.9999964e-01 3.7401225e-07]\n",
      " [9.9999952e-01 4.2785780e-07]\n",
      " [9.9999976e-01 2.1060133e-07]\n",
      " [9.9999964e-01 3.0967431e-07]\n",
      " [9.9999952e-01 4.3253439e-07]\n",
      " [9.9999976e-01 2.3959694e-07]\n",
      " [9.9999988e-01 1.6853413e-07]\n",
      " [9.9999976e-01 1.9702938e-07]\n",
      " [9.9999976e-01 2.9427369e-07]\n",
      " [9.9999964e-01 3.6329661e-07]\n",
      " [9.9999976e-01 2.7627902e-07]\n",
      " [9.9999976e-01 2.5699265e-07]\n",
      " [9.9999976e-01 2.1927600e-07]\n",
      " [9.9999988e-01 1.7219152e-07]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [9.9999976e-01 1.8155940e-07]]\n",
      "length of predictions- 40\n",
      "for prediction 0\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 1\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 2\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 3\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 4\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 5\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 6\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 7\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 8\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 9\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 10\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 11\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 12\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 13\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 14\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 15\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 16\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 17\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 18\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 19\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 20\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 21\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 22\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 23\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 24\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 25\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 26\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 27\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 28\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 29\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 30\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 31\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 32\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 33\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 34\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 35\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 36\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 37\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 38\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 39\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "C:\\Users\\STSC\\Desktop\\CV-Indoor\\Batch_Predictions\\Stairs\\VID_20191202_123759111.mp4\n",
      "Prediction:::\n",
      "[[9.9972194e-01 2.7802831e-04]\n",
      " [9.9994087e-01 5.9096794e-05]\n",
      " [9.9978358e-01 2.1639337e-04]\n",
      " [9.9996769e-01 3.2258715e-05]\n",
      " [9.9997854e-01 2.1476242e-05]\n",
      " [9.9994135e-01 5.8606627e-05]\n",
      " [9.9989426e-01 1.0569541e-04]\n",
      " [9.9995732e-01 4.2702326e-05]\n",
      " [9.9987102e-01 1.2901955e-04]\n",
      " [9.9992204e-01 7.7898061e-05]\n",
      " [9.9996984e-01 3.0204059e-05]\n",
      " [9.9997318e-01 2.6861420e-05]\n",
      " [9.9994278e-01 5.7195062e-05]\n",
      " [9.9988019e-01 1.1975697e-04]\n",
      " [9.9995780e-01 4.2182397e-05]\n",
      " [9.9995410e-01 4.5915727e-05]\n",
      " [9.9996996e-01 3.0040235e-05]\n",
      " [9.9990129e-01 9.8737961e-05]\n",
      " [9.9976927e-01 2.3078712e-04]\n",
      " [9.9992609e-01 7.3923678e-05]\n",
      " [9.9996698e-01 3.3027653e-05]\n",
      " [9.9994636e-01 5.3640946e-05]\n",
      " [9.9993336e-01 6.6610293e-05]\n",
      " [9.9989855e-01 1.0147403e-04]\n",
      " [9.9999011e-01 9.9177132e-06]\n",
      " [9.9997735e-01 2.2601953e-05]\n",
      " [9.9992561e-01 7.4413394e-05]\n",
      " [9.9995947e-01 4.0478913e-05]\n",
      " [9.9996531e-01 3.4708683e-05]\n",
      " [9.9994969e-01 5.0327635e-05]\n",
      " [9.9996901e-01 3.0992749e-05]\n",
      " [9.9995756e-01 4.2455289e-05]\n",
      " [9.9997115e-01 2.8832746e-05]\n",
      " [9.9999058e-01 9.4455017e-06]\n",
      " [9.9996281e-01 3.7199654e-05]\n",
      " [9.9998593e-01 1.4035424e-05]\n",
      " [9.9992299e-01 7.6964090e-05]\n",
      " [9.9995458e-01 4.5410641e-05]\n",
      " [9.9993777e-01 6.2191364e-05]\n",
      " [9.9984515e-01 1.5483539e-04]]\n",
      "length of predictions- 40\n",
      "for prediction 0\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 1\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 2\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 3\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 4\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 5\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 6\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 7\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 8\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 9\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 10\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 11\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 12\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 13\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 14\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 15\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 16\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 17\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 18\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 19\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 20\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 21\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 22\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 23\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 24\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 25\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 26\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 27\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 28\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 29\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 30\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 31\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 32\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 33\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 34\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 35\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 36\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 37\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 38\n",
      "index of max predicition class \n",
      "Stairs-  0\n",
      "for prediction 39\n",
      "index of max predicition class \n",
      "Stairs-  0\n"
     ]
    }
   ],
   "source": [
    "# perform prediction using video data on LSTM model\n",
    "for video_path in file_list:\n",
    "    print(video_path)\n",
    "    \n",
    "    #step 3.2 call function passing a video_path and returning the array of images of SEQUENCE_LENGTH\n",
    "    images = grabImagesFromVideo_PreProcess_for_MobileNet_FeatureExtractor(video_path)\n",
    "    features = grabImagesFromVideo_Process_with_MobileNet_FeatureExtractor(video_path, feature_extraction_model)\n",
    "    \n",
    "    #save the array of feature vectors to file same location but extension .npy\n",
    "    output_path = video_path.replace('.mp4', '.npy')\n",
    "    fid = open(output_path, \"wb\")\n",
    "    np.save(output_path, features)\n",
    "    \n",
    "    #STEP 4: take the array of vectors all_features and convert it to a tensor for input into our LSTM model\n",
    "    tensor_input = tf.convert_to_tensor(features, dtype=tf.float32)\n",
    "    #print(tensor_input)\n",
    "\n",
    "    #create tensor needed from processed video\n",
    "    #current array of feature vectors representing images in video clip called  all_features\n",
    "    prediction= model.predict(tensor_input, batch_size=1)\n",
    "    print('Prediction:::')\n",
    "    print(prediction)\n",
    "    print(\"length of predictions- \" + str(len(prediction)))\n",
    "\n",
    "    i=0\n",
    "    for p in prediction:\n",
    "        print(\"for prediction \" + str(i))\n",
    "        print(\"index of max predicition class \")\n",
    "        if(np.argmax(p)==0):\n",
    "            print('Stairs- ',np.argmax(p))\n",
    "        elif(np.argmax(p)==1):\n",
    "            print('Doors- ',np.argmax(p))\n",
    "        else:\n",
    "            print('Others- ',np.argmax(p))\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
